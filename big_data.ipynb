{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guia Conceitual sobre **Big Data**\n",
    "\n",
    "## O que é **Big Data**?\n",
    "\n",
    "**Big Data** refere-se a um conjunto de dados massivos, complexos e em constante crescimento, que não podem ser tratados eficientemente com as tecnologias tradicionais de processamento de dados. A expressão é usada tanto para descrever os dados em si quanto para as tecnologias desenvolvidas para processá-los e analisá-los.\n",
    "\n",
    "### Senta que lá vem história...\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/NRaQSS4XnzU?si=0D_ir_RhcUwyAEaS\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "**Peter Lyman** e **Hal R.**, em outubro de 2000, na University of California, em Berkeley, publicaram: `How Much Information?`. Foi o primeiro estudo abrangente sobre quantificar, em termos de armazenamento de computador, a quantidade total de informações novas e originais (sem contar cópias) criadas no mundo anualmente e armazenadas em quatro mídias físicas: papel, filme, óptico (CDs e DVDs) e magnético. O estudo concluiu que, em 1999, o mundo produziu cerca de 1,5 exabytes de informações exclusivas, ou cerca de 250 megabytes para cada homem, mulher e criança na Terra. Também constatou que: 'uma grande quantidade de informações únicas é criada e armazenada por indivíduos'.\n",
    "\n",
    "Naquele período, em um evento chamado 'Democratização dos dados', esses mesmos autores, Lyman e Varian, afirmaram que: 'até hoje, a maioria das informações textuais é 'nascida digital' e dentro de alguns anos isso também será verdade para imagens'.\n",
    "\n",
    "Os mesmos pesquisadores identificaram que o mundo produziu cerca de 5 exabytes de novas informações em 2002 e que 92% das novas informações foram armazenadas em mídia magnética, principalmente em discos rígidos.\n",
    "\n",
    "Em fevereiro de 2001, Doug Laney, analista do Grupo Meta, publicou uma nota de pesquisa intitulada 'Gestão de dados 3D: Controlar o `volume de dados`, `velocidade` e `variedade`'. Uma década mais tarde, aparecem os `3 Vs` - as três dimensões geralmente aceitas que definem big data e que, podemos dizer, estão vinculadas com aqueles conceitos de Laney.\n",
    "\n",
    "Em **2005**, **Roger Mougalas**, da O'Reilly Media, cunhou o termo `big data` pela primeira vez, apenas um ano depois de criar o termo `Web 2.0`. Na época, referia-se a um grande conjunto de dados que é quase impossível de gerenciar e processar usando as ferramentas tradicionais de business intelligence. Nesse mesmo ano, o **Hadoop** foi criado pelo Yahoo!, construído sobre o MapReduce do Google. O objetivo era indexar toda a World Wide Web; atualmente, o Hadoop de código aberto é usado por muitas organizações para processar grandes quantidades de dados (SILVA, 2019, on-line).\n",
    "\n",
    "# 1. **Dados**(Data)\n",
    "Dados são elementos brutos que, quando processados, se transformam em informações estruturadas. Eles são a matéria-prima essencial para a produção de conhecimento e insights. Isoladamente, os dados têm pouco ou nenhum significado, pois, por si só, carecem de contexto ou estrutura. Para que os dados adquiram relevância e façam sentido, é necessário associá-los a outros elementos informacionais e contextuais. Somente após essa integração é que os dados podem ser interpretados, gerando informações que, por sua vez, servem de base para a construção de conhecimento.\n",
    "\n",
    "# 2. **Informação** (Information)\n",
    "A informação constitui o resultado do processamento e da organização dos dados, transformando-os em elementos dotados de significado e relevância. Trata-se da consolidação dos dados de forma a fundamentar a geração de conhecimento. Dados, informação e conhecimento estão intrinsecamente interligados, sendo que o conhecimento ocupa uma posição de destaque nesse processo, ao representar a compreensão aprofundada e a aplicação contextualizada da informação de maneira crítica e reflexiva.\n",
    "\n",
    "| **Dado**                                           | **Informação**                                    | **Conhecimento**                                                                                                          |\n",
    "|----------------------------------------------------|--------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n",
    "| Representações básicas e brutas de fatos ou eventos. Sozinhos, não possuem valor interpretativo ou para tomadas de decisão. | Dados processados e organizados de forma a terem relevância e propósito.          | Integração de informações processadas e refinadas pela mente humana, com reflexão, síntese e contexto. Geralmente subjetivo e difícil de formalizar.      |\n",
    "| Estruturação fácil e direta.                       | Necessita de contexto para ter significado.       | Complexo e de difícil estruturação formal.                                                                                 |\n",
    "| Pode ser facilmente coletado por máquinas.         | Exige interpretação e análise para ser útil.      | Difícil de ser capturado ou replicado por máquinas.                                                                       |\n",
    "| Geralmente quantificado, organizado e categorizado.| Requer consenso sobre o significado dos dados.    | Subjetivo, varia com a experiência e habilidades de cada pessoa.                                                          |\n",
    "| Fácil transmissão e armazenamento.                 | Permite cálculos e operações analíticas.          | Transferência difícil, pois depende de experiências e intuições pessoais.                                                 |\n",
    "\n",
    "# 3. Data**set**\n",
    "Um **conjunto de dados**, comumente denominado `dataset`, refere-se ao principal insumo para processos de análise de dados. Trata-se de um arquivo que contém centenas, ou até milhares, de informações relativas a um tema específico, organizado de maneira a viabilizar sua manipulação e interpretação. Esse arquivo pode assumir diversos formatos, tais como planilhas do `Excel (XLS)`, arquivos `CSV`, `TXT`, `JSON`, ou `XML`. Em essência, um dataset é uma coleção organizada de dados dispostos em linhas e colunas, amplamente utilizada em análises estatísticas e de dados.\n",
    "\n",
    "Com o exponencial crescimento da quantidade de dados gerados pela internet e o advento das mídias sociais, torna-se imprescindível gerenciar e armazenar essas informações de forma estruturada. Os dados, por sua vez, podem ser classificados em estruturados, não estruturados e semiestruturados, de acordo com o seu nível de organização e as técnicas empregadas para seu armazenamento e gerenciamento.\n",
    "\n",
    "| **Tipo de Dados**          | **Definição**                                                                                                                                      | **Exemplos**                                                                                                           |\n",
    "|----------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Dados Estruturados**      | Dados organizados de forma rígida em formatos predefinidos, como tabelas com linhas e colunas. São facilmente armazenados e analisados em bancos de dados relacionais. | Registros financeiros, planilhas, informações cadastrais, sistemas SQL.                                               |\n",
    "| **Dados Não Estruturados**  | Informações que não seguem um padrão de organização fixo, tornando seu processamento mais complexo. Necessitam de técnicas avançadas para extração de valor. | Textos, imagens, vídeos, áudios, e-mails, postagens em redes sociais.                                                  |\n",
    "| **Dados Semiestruturados**  | Dados que apresentam uma organização parcial, com elementos identificáveis, mas sem a rigidez dos dados estruturados. Permitem certo nível de categorização. | Arquivos XML, JSON, que possuem marcas ou etiquetas para facilitar a manipulação.                                      |\n",
    "\n",
    "\n",
    "## As **Três Vs** do **Big Data**\n",
    "\n",
    "Os três pilares do **Big Data** são conhecidos como os **Três Vs**:\n",
    "\n",
    "1. **Volume**: Refere-se à quantidade imensa de dados gerados diariamente. As fontes podem incluir redes sociais, dispositivos IoT, transações financeiras, entre outras.\n",
    "   \n",
    "2. **Variedade**: Os dados vêm em diversos formatos, como textos, imagens, vídeos, dados estruturados (bancos de dados) e dados não estruturados (e-mails, posts em redes sociais).\n",
    "\n",
    "3. **Velocidade**: A rapidez com que os dados são gerados e processados. Com a ascensão de tecnologias em tempo real, a velocidade tornou-se um componente essencial para gerar insights rapidamente.\n",
    "\n",
    "## **Veracidade** e **Valor**\n",
    "\n",
    "Além dos **Três Vs**, outros dois aspectos são cruciais:\n",
    "\n",
    "- **Veracidade**: A qualidade e confiabilidade dos dados. Em muitos casos, grandes volumes de dados podem ser imprecisos ou desorganizados, o que pode prejudicar a análise.\n",
    "\n",
    "- **Valor**: O benefício que se pode extrair dos dados. Coletar dados em grande volume não tem utilidade se eles não gerarem insights acionáveis.\n",
    "\n",
    "## Tools\n",
    "\n",
    "- **Hadoop**: Plataforma de software desenvolvida em Java, projetada para computação distribuída em ambientes de clusters. Essa tecnologia é particularmente eficaz para o processamento de grandes volumes de dados, oferecendo robustez e suporte à tolerância a falhas, permitindo que as operações continuem mesmo na ocorrência de erros em um ou mais nós do cluster.\n",
    "\n",
    "- **MapReduce**: Framework inovador criado pela Google que facilita a realização de computações paralelas em extensas coleções de dados distribuídos em clusters de computadores. O modelo MapReduce divide as tarefas em duas fases principais: \"Map\", onde os dados são processados e transformados, e \"Reduce\", onde os resultados intermediários são agregados e consolidados, promovendo eficiência e escalabilidade no processamento de grandes volumes de dados.\n",
    "\n",
    "- **Linguagens de script**: Conjunto de linguagens de programação, como Python, que se mostram particularmente adequadas para o trabalho com big data. Essas linguagens oferecem versatilidade e facilidade de uso, permitindo a manipulação, análise e visualização de dados de forma ágil e eficiente, além de possuírem bibliotecas robustas para o desenvolvimento de soluções analíticas.\n",
    "\n",
    "- **Visual Analytics**: Abordagem metodológica que visa a análise de grandes volumes de dados, proporcionando saídas em formatos visuais ou gráficos. Essa técnica combina técnicas de análise de dados com visualização, permitindo que padrões, tendências e insights sejam facilmente identificados e compreendidos, facilitando a tomada de decisões fundamentadas.\n",
    "\n",
    "- **Processamento de Linguagem Natural (PLN)**: Ramo da inteligência artificial dedicado à análise e compreensão de textos escritos. O PLN permite que máquinas interpretem, processem e extraiam significados a partir da linguagem humana, possibilitando aplicações como análise de sentimentos, tradução automática e assistentes virtuais.\n",
    "\n",
    "- **In-Memory Analytics**: Técnica de processamento de big data que é realizada diretamente na memória do computador, com o objetivo de maximizar a velocidade das análises. A tecnologia de in-memory analytics representa um avanço significativo, uma vez que minimiza a necessidade de acesso a disco, acelerando o tempo de resposta e permitindo análises em tempo real de grandes conjuntos de dados.\n",
    "\n",
    "- **Data Lake**: Estrutura de armazenamento que permite a retenção de dados em seu formato bruto, seja ele estruturado, semiestruturado ou não estruturado. Os data lakes possibilitam a centralização de grandes volumes de dados, promovendo maior flexibilidade para análises futuras, uma vez que os dados não precisam ser transformados antes do armazenamento.\n",
    "\n",
    "- **Machine Learning**: Subcampo da inteligência artificial que se concentra no desenvolvimento de algoritmos e modelos que permitem que sistemas computacionais aprendam com os dados, identificando padrões e fazendo previsões sem a necessidade de programação explícita. O aprendizado de máquina tem aplicações em diversas áreas, incluindo reconhecimento de imagem, detecção de fraudes e recomendações personalizadas.\n",
    "\n",
    "- **Inteligência Artificial (IA)**: Campo abrangente da computação que se propõe a desenvolver sistemas capazes de realizar tarefas que, normalmente, requereriam inteligência humana. A IA abrange subáreas como aprendizado de máquina, visão computacional, e processamento de linguagem natural, sendo utilizada em soluções que vão desde assistentes virtuais até diagnósticos médicos automatizados.\n",
    "\n",
    "- **Business Intelligence (BI)**: Conjunto de tecnologias e práticas que visam a coleta, análise e apresentação de informações empresariais. O BI auxilia na tomada de decisões, proporcionando relatórios e dashboards interativos que facilitam a visualização de dados e a identificação de tendências e oportunidades de negócios.\n",
    "\n",
    "- **IoT (Internet das Coisas)**: Rede de dispositivos conectados à internet que coletam e trocam dados entre si. A IoT tem transformado diversos setores ao possibilitar a coleta em tempo real de informações, otimizando processos e permitindo a análise preditiva a partir dos dados gerados por esses dispositivos.\n",
    "\n",
    "## **Hadoop**\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/0/0e/Hadoop_logo.svg)\n",
    "\n",
    "## O que é Hadoop?\n",
    "\n",
    "Hadoop é uma plataforma de software de código aberto que permite o processamento distribuído de grandes volumes de dados em clusters de computadores. Desenvolvido em Java, o Hadoop é projetado para escalar horizontalmente, permitindo que novas máquinas sejam adicionadas ao sistema à medida que a demanda por armazenamento e processamento aumenta.\n",
    "\n",
    "## Arquitetura do Hadoop\n",
    "\n",
    "A arquitetura do Hadoop é composta por quatro componentes principais:\n",
    "\n",
    "1. **Hadoop Distributed File System (HDFS)**\n",
    "   - Sistema de arquivos distribuído que armazena grandes volumes de dados de forma redundante.\n",
    "   - Divide arquivos em blocos e os distribui por diferentes nós do cluster.\n",
    "   - Proporciona tolerância a falhas através da replicação dos dados.\n",
    "\n",
    "2. **YARN (Yet Another Resource Negotiator)**\n",
    "   - Sistema de gerenciamento de recursos que permite a distribuição eficiente de tarefas no cluster.\n",
    "   - Facilita a execução simultânea de várias aplicações, otimizando o uso dos recursos disponíveis.\n",
    "\n",
    "3. **MapReduce**\n",
    "   - Modelo de programação que permite o processamento paralelo de grandes conjuntos de dados.\n",
    "   - Consiste em duas etapas:\n",
    "     - **Map**: Processa e transforma os dados.\n",
    "     - **Reduce**: Agrega e consolida os resultados intermediários.\n",
    "\n",
    "4. **Hadoop Common**\n",
    "   - Conjunto de bibliotecas e utilitários que suportam os outros componentes do Hadoop.\n",
    "   - Fornece as funções necessárias para a operação do sistema.\n",
    "\n",
    "## Vantagens do Hadoop\n",
    "\n",
    "- **Escalabilidade**: A capacidade de adicionar novos nós ao cluster conforme a demanda aumenta.\n",
    "- **Custo-efetividade**: Utiliza hardware comum e de baixo custo para armazenamento e processamento de dados.\n",
    "- **Tolerância a falhas**: Os dados são replicados em múltiplos nós, garantindo a continuidade das operações em caso de falhas.\n",
    "- **Flexibilidade**: Suporta diferentes tipos de dados, incluindo estruturados, semiestruturados e não estruturados.\n",
    "\n",
    "## Ecossistema Hadoop\n",
    "\n",
    "O Hadoop possui um rico ecossistema de ferramentas que ampliam suas capacidades. Algumas das ferramentas mais comuns incluem:\n",
    "\n",
    "- **Apache Hive**: Uma infraestrutura de data warehouse que permite consultas em dados armazenados no HDFS usando uma linguagem semelhante ao SQL.\n",
    "- **Apache Pig**: Uma plataforma de análise de dados que fornece uma linguagem de script para trabalhar com dados em HDFS.\n",
    "- **Apache HBase**: Um banco de dados NoSQL que funciona em cima do HDFS e permite a leitura e gravação de dados em tempo real.\n",
    "- **Apache Spark**: Um motor de processamento de dados rápido e de uso geral que pode operar em conjunto com o Hadoop para análises em tempo real.\n",
    "\n",
    "## Casos de Uso do Hadoop\n",
    "\n",
    "- **Análise de Big Data**: Empresas utilizam Hadoop para processar e analisar grandes volumes de dados gerados por suas operações diárias.\n",
    "- **Armazenamento de Dados**: O HDFS é utilizado para armazenar dados de forma escalável e redundante.\n",
    "- **Processamento de Logs**: Muitas organizações utilizam Hadoop para analisar logs de servidores e identificar padrões de comportamento.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "O Hadoop se estabeleceu como uma das principais plataformas para o processamento de grandes volumes de dados. Sua arquitetura robusta, aliada à flexibilidade e escalabilidade, permite que organizações em diversos setores extraiam valor significativo das informações geradas em seus processos. O contínuo desenvolvimento de ferramentas no ecossistema Hadoop garante que ele permaneça relevante e adaptável às necessidades de análise de dados contemporâneas.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Arquitetura do Big Data**\n",
    "\n",
    "A arquitetura de um sistema de **Big Data** geralmente inclui:\n",
    "\n",
    "- **Coleta de Dados**: Ferramentas como sensores, logs de servidores e APIs coletam dados de diversas fontes.\n",
    "  \n",
    "- **Armazenamento**: Como os dados são grandes demais para bancos de dados tradicionais, utilizam-se tecnologias como o **Hadoop**, **NoSQL** (e.g., MongoDB, Cassandra) e **Data Lakes**.\n",
    "\n",
    "- **Processamento**: Ferramentas como **Apache Spark** e **MapReduce** são usadas para processar os dados em paralelo, melhorando a eficiência.\n",
    "\n",
    "- **Análise**: Algoritmos de **Machine Learning** e **Data Mining** são aplicados para descobrir padrões e gerar insights.\n",
    "\n",
    "## **Vantagens do Big Data**\n",
    "\n",
    "- **Melhor tomada de decisão**: As análises baseadas em grandes volumes de dados permitem decisões mais informadas e estratégicas.\n",
    "- **Personalização**: Empresas podem personalizar produtos e serviços com base no comportamento dos clientes.\n",
    "- **Previsões mais precisas**: A análise de grandes conjuntos de dados possibilita a criação de previsões mais confiáveis.\n",
    "\n",
    "## **Desafios do Big Data**\n",
    "\n",
    "- **Armazenamento e Processamento**: Lidar com dados massivos exige infraestrutura robusta e escalável.\n",
    "- **Privacidade e Segurança**: Com grandes quantidades de dados pessoais, proteger a privacidade e a segurança dos dados se torna uma prioridade.\n",
    "- **Qualidade dos Dados**: Dados imprecisos ou incompletos podem levar a análises erradas.\n",
    "\n",
    "## **Aplicações do Big Data**\n",
    "\n",
    "1. **Saúde**: Monitoramento de pacientes, análise de exames e detecção precoce de doenças.\n",
    "2. **Marketing**: Criação de campanhas personalizadas com base no comportamento de clientes.\n",
    "3. **Finanças**: Detecção de fraudes e análise de investimentos com base em grandes volumes de dados.\n",
    "4. **Manufatura**: Otimização de cadeias de produção e manutenção preditiva.\n",
    "5. **Ciência de Dados**: Descobertas em várias áreas, desde astronomia até biologia, utilizando a análise de grandes volumes de dados.\n",
    "\n",
    "## Ferramentas Populares de **Big Data**\n",
    "\n",
    "- **Hadoop**: Framework de código aberto para o processamento e armazenamento de grandes volumes de dados.\n",
    "- **Apache Spark**: Ferramenta de processamento de dados em tempo real, projetada para ser mais rápida que o Hadoop.\n",
    "- **NoSQL**: Bancos de dados como **MongoDB** e **Cassandra** que armazenam dados não estruturados.\n",
    "- **Tableau**: Ferramenta de visualização de dados que facilita a criação de dashboards interativos a partir de grandes volumes de dados.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "O **Big Data** revolucionou a maneira como as empresas, governos e cientistas lidam com a informação. Embora apresente desafios significativos, como a questão da privacidade e o processamento eficiente de grandes volumes de dados, suas aplicações e benefícios são vastos e transformadores. Com as ferramentas e abordagens corretas, o **Big Data** possibilita uma visão mais clara e estratégica sobre diversas áreas da sociedade e do mercado.\n",
    "\n",
    "---\n",
    "\n",
    "**Referências**:\n",
    "\n",
    "- McAfee, A., & Brynjolfsson, E. (2012). \"Big Data: The Management Revolution\". *Harvard Business Review*.\n",
    "- Marr, B. (2015). *Big Data: Using SMART Big Data, Analytics and Metrics to Make Better Decisions and Improve Performance*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidade 2\n",
    "\n",
    "O planejamento do uso eficaz das Tecnologias da Informação (TIs) realmente se torna essencial para as organizações, especialmente no contexto atual de rápidas mudanças e inovações. O alinhamento entre o Planejamento Estratégico de Negócios (PEN) e o Planejamento Estratégico de Sistemas de Informação (PESI) é crucial, pois permite que as empresas integrem suas metas de negócios com as soluções tecnológicas, garantindo que as TIs suportem e impulsionem as estratégias organizacionais.\n",
    "\n",
    "Esse alinhamento não só ajuda a identificar oportunidades para a adoção de novas tecnologias, mas também facilita a adaptação às mudanças do mercado e a resposta a desafios emergentes. Além disso, uma abordagem integrada pode resultar em maior eficiência operacional, melhor tomada de decisões e um uso mais estratégico dos recursos tecnológicos.\n",
    "\n",
    "Para que o PESI seja verdadeiramente eficaz, é fundamental que ele envolva a colaboração de diversas áreas da organização, promovendo uma visão holística das necessidades e prioridades. Dessa forma, o planejamento se torna uma ferramenta dinâmica, capaz de responder proativamente às exigências do ambiente de negócios.\n",
    "\n",
    "Assim, investir no desenvolvimento de um PESI alinhado ao PEN pode proporcionar uma vantagem competitiva significativa, permitindo que a organização se adapte e cresça em um cenário em constante evolução.\n",
    "\n",
    "| Aspecto                       | Planejamento Estratégico de Negócios (PEN) | Planejamento Estratégico de Sistemas de Informação (PESI) |\n",
    "|-------------------------------|-------------------------------------------|---------------------------------------------------------|\n",
    "| **Objetivo**                  | Definir a visão, missão e metas da organização | Alinhar a TI com as estratégias de negócios               |\n",
    "| **Foco**                      | Direção geral e objetivos de longo prazo  | Implementação e uso eficaz das tecnologias de informação   |\n",
    "| **Escopo**                    | Abrange todas as áreas da organização      | Focado em sistemas de informação e tecnologias            |\n",
    "| **Colaboração**               | Envolve diversas áreas (finanças, marketing, etc.) | Necessita de colaboração entre TI e outras áreas          |\n",
    "| **Adaptação às mudanças**     | Responde a mudanças do mercado e ambiente | Permite adaptação rápida às inovações tecnológicas        |\n",
    "| **Métricas de sucesso**       | Crescimento, lucratividade, participação de mercado | Eficiência operacional, ROI em TI, satisfação do usuário  |\n",
    "| **Perspectiva temporal**      | Longo prazo (3-5 anos ou mais)           | Médio a longo prazo (normalmente 1-3 anos)               |\n",
    "| **Ferramentas**               | Análise SWOT, Balanced Scorecard          | Modelos de arquitetura de TI, planejamento de capacidade    |\n",
    "| **Benefícios**                | Direcionamento estratégico, vantagem competitiva | Melhoria na tomada de decisões, maior eficiência           |\n",
    "\n",
    "Independentemente da terminologia utilizada, pode-se identificar um conjunto de componentes que caracterizam o contexto de um processo de planejamento estratégico de Sistemas de Informação, que podem ser:\n",
    "\n",
    "\n",
    "| Dimensão                | Elementos Principais                                                  |\n",
    "|------------------------|---------------------------------------------------------------------|\n",
    "| **Dimensão Tecnológica** |                                                                     |\n",
    "| Infraestrutura          | Hardware, software e comunicações                                   |\n",
    "| Aplicações Internas     | Intranet, Sistemas Empresariais (ERP, SAD, SIG)                    |\n",
    "| Aplicações Externas     | CRM, Call Center, Extranet                                          |\n",
    "| **Dimensão de Gestão**   |                                                                     |\n",
    "| Processos              | Modelagem de negócio                                                |\n",
    "| Pessoas                | Aprendizagem e desenvolvimento humano                               |\n",
    "| Abordagens de Gestão   | Mudança, cultura organizacional e liderança                         |\n",
    "\n",
    "Atualmente, é possível contar com o apoio da tecnologia para a tomada de decisões cada vez mais acertadas nos negócios. O conceito de BI (Business Intelligence) está relacionado ao processo de coleta de dados de qualquer sistema e funciona como uma ferramenta tecnológica que concentra todas as informações relacionadas à operação do negócio, fornecendo uma gestão de informação inteligente e uma análise de dados avançada para o apoio necessário para a tomada de decisões estratégicas de maneira inteligente, por meio da integração entre os diversos sistemas que a empresa tem (por exemplo, ERP, CRM etc.). O BI reúne todas as informações em um único local, chamado de `Data Warehouse`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
